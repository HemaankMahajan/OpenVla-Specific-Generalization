{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
      },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers>=4.45.0 timm accelerate bitsandbytes\n",
        "!pip install -q tensorflow-datasets tensorflow-hub\n",
        "!pip install -q -U bitsandbytes"
      ],
      "metadata": {
        "id": "qwpIHuVvRoZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForVision2Seq, AutoProcessor, AutoConfig\n",
        "from PIL import Image\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import sys\n",
        "import os"
      ],
      "metadata": {
        "id": "JkrVsCY9WKma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the SOTA Model Weights from Hugging Face\n",
        "model_id = \"openvla/openvla-7b\"\n",
        "save_directory = \"./vla_model_local\"\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(model_id, trust_remote_code=True)"
      ],
      "metadata": {
        "id": "QH_H4qI4WVkq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475,
          "referenced_widgets": [
            "1cc7b885c54a4641bfab2eeb592c5a16",
            "d18f82d01e0d4c1592226b7cb8d96312",
            "edddcbf5bf624cfa99d1b95b6243c7de",
            "0f52700294b6440e8547e47031774405",
            "f4426a5888484efe8e4b5e8268451015",
            "209248b005b14e989ea68d1f2ec1f79e",
            "961c49b41f634b548ae0ebb22ac8bbe1",
            "2366f09a6c7a42fab3fa661ae29c90f3",
            "3528b750cf7e4f32a2538a60fc05c9eb",
            "3d12cfe8ee8142ac931e0c8b794b9d81",
            "ce437f1d62d34d8599b9391d5a1a2709",
            "0b53fd349b324ee8aa01c43895575739",
            "53a9b777182d4101ab0a13ae8009051b",
            "a91d222a59354e0ab7a80c9f3f9ab532",
            "a6de04e7ed9d4296a06a45e73b40d8bd",
            "18e6263cc6a14eacbac9c85efd6510d4",
            "9a516507e77044b9904023ff19f2b707",
            "2fcf7f4c788e474cbc5def888a1113c9",
            "dee0beab0bf64fa38c8e2db0b53bc54e",
            "91cc3291223844b0b714b0c21c4c3c64",
            "b6d3d2bc270a494382a85ce51168eca8",
            "e97079dc7ac14eff8d475557823ea68f",
            "e8cf837be2824718a161db0204300ef4",
            "746bec5cd1a64af98b8d93371b6444ad",
            "2ebebd35cad3473c8d25ece07ca53e68",
            "cbbb898cf2db469b8371a4f25122d31b",
            "18ed6276b746411189e03fd60e2068d9",
            "04964e40f2244094a4fee6f485f949d6",
            "3d666d421adc4b5b9a85fab9e227008f",
            "33d6e45b1a4b4174b0ca8be7a85fb4a3",
            "66f19b6a7dfd42cbb8f57d60cd919d2f",
            "5245b6acb2304a018b4631c5424300e1",
            "80dd99a1288d467f865486742b25dfac",
            "f645c45992884f7391e78466b04164fc",
            "6de08a0c41a44eefa0193ac9a9e9d8b0",
            "57e40394e7954d698689e9e7e81e1a91",
            "9588a70f4d4b460d928de0a85de65833",
            "3492d0d4f82b447e9f080adc8cafcdea",
            "a6ceb602e1a5473791885ad9c8a5dfda",
            "e63d670de88041ba96fa370b45d4d1b9",
            "d107eee25402438bb6e37e9e391c32a4",
            "84e53532403f44048178938bdd8e9173",
            "55ce9d09cd50448ea9de1c5a1d75e8b5",
            "bd9b43b0ed644d9a81bd109adb92ed1b",
            "bc9cf065a63c476dbbd431f48edd1bf3",
            "b81d55a2ecc042439b545443cdfb9950",
            "9e83f273d2244b62a532fb5a22facd1f",
            "42e89a9d2ba24d7a9f0865e7cac935f4",
            "61d4beab6070409cad44a0d119465b23",
            "f50f66a443af46f0801e15ce468aa70b",
            "c0fd9ce388b84f0f94605c8fc13f1b99",
            "d8acd29860a54312abc3387eb5b87ead",
            "01358aad3afb4e08a7d9b888480732f6",
            "d56e500ea338499faa46e6526476b7af",
            "4596e32b57c8482e86168d9e9ba0a3d1",
            "fcd649d494b541cb9521efbe9bb0eff5",
            "97acd1c4ad1047c3bc4bce23bb83d782",
            "63c5569aeb1342ce828e0d941714995e",
            "f98c210e7a92445ba11d48def9de836a",
            "45b51e7519534c2884a3675c10919bab",
            "baee1d3a9927492daab492961a3fed6e",
            "4b276adeaab545118ce5d52f178b304b",
            "f1c6662e657c4901aeb18280138edf39",
            "815a8072dee146e3930a27008ff23bb8",
            "8f55b43618b14ba2ba8588079615f655",
            "ff99b3e16b6e46b3997934e9a88b5430",
            "6692b2daebf745bcb414f622758acc35",
            "ca1852a5ade04b22a94801e5c4396d1d",
            "99d8cf4008954830818a390e0e021283",
            "257cd1f7453640b7b4d08cd97d94a226",
            "aa00e53019ef48edafaad698713b2df8",
            "03f735141843495583375691b7e2206d",
            "db044bd6285149d69e3ee8439f785e05",
            "94041742cdde4001990496ce3aefabc9",
            "9815500ab7304b37a727b16bab6b0dc4",
            "a37a4c8841ac40de88071d1e40f5b3e7",
            "4c9cf715a6b64e2cb4ec44ac9731f311",
            "cc0b77e6d434443391075bfa6b845248",
            "8cb5a3d1794b44d5a6a3a436858e743d",
            "820e5398745846d080c9f5913efabb8d",
            "05c44ea472e04ba1b75705f07d26b054",
            "c5763d37d05e4390a20ec7ecc400e470",
            "6d8625adae9e4605a551401c7de7ea03",
            "c79c1aa9c236470dac16626af2c88b1e",
            "3522d5da53fd4daa85abe872eda40dba",
            "9011935ea40c40a8ad89d125b60907da",
            "59aea81202db44dc9c6cf0900b5a4271",
            "c6e6e740e4b342769d21b23b2e3bf58b"
          ]
        },
        "outputId": "f33e536d-a41b-4edd-97bc-f07d658c92c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "processor_config.json:   0%|          | 0.00/130 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1cc7b885c54a4641bfab2eeb592c5a16"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "processing_prismatic.py: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0b53fd349b324ee8aa01c43895575739"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/openvla/openvla-7b:\n",
            "- processing_prismatic.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "preprocessor_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e8cf837be2824718a161db0204300ef4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f645c45992884f7391e78466b04164fc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bc9cf065a63c476dbbd431f48edd1bf3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fcd649d494b541cb9521efbe9bb0eff5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/21.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6692b2daebf745bcb414f622758acc35"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/552 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cc0b77e6d434443391075bfa6b845248"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.models.auto.modeling_auto import AutoModelForVision2Seq\n",
        "config = AutoConfig.from_pretrained(model_id, trust_remote_code=True)\n",
        "\n",
        "try:\n",
        "    vla = AutoModelForVision2Seq.from_config(config, trust_remote_code=True)\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# Applying the patch globally to the remote class\n",
        "for module_name, module in sys.modules.items():\n",
        "    if \"modeling_prismatic\" in module_name:\n",
        "        if hasattr(module, \"OpenVLAForActionPrediction\"):\n",
        "            setattr(module.OpenVLAForActionPrediction, \"_supports_sdpa\", True)\n",
        "            print(f\"✅ Globally patched: {module_name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297,
          "referenced_widgets": [
            "a076676150744ae4b6fce03bddbfc2bb",
            "351ff713f7b5406899edc85f62d75019",
            "9630ec9237734751a9b44b85202d4b8c",
            "44e88603f0d84f2797d0fdfdc7497d03",
            "4d7ea810a8824ecd95dfbe2e09267c21",
            "6219c796518c40bc9609e6b62c05b9a3",
            "5fadae7e87434317bf2976c9d1438b38",
            "bdc1814d0c8344d388e087867559f2bb",
            "8d8f61aa46af4b3e9696148ae2d0e479",
            "de4ce7ac1f6e42a8bde0476140423b75",
            "9451fa00cf3446c2ac28517dc29b3818",
            "86f44d9e3abf42dab26a3c992c00b4bf",
            "76daeb26bc1e45999a995d09b3626ab0",
            "f7bcdf835dca4cfa920ced68cb6c99f6",
            "f57e519c35eb4b7d8bd2d226062e8c1c",
            "f3a5c0df0556416381a164c31f214d69",
            "4a64d385d28e42b3ad6a5d07491f5bb9",
            "8e8937dc041b4b8ea5ec320d3a4604c8",
            "9a17fc4a63bd4bbb9bdf395bba143805",
            "3f13a41b12eb4e90ad154ef54b880581",
            "caf1239a1849452b864971bfd4233ba5",
            "24f747e7001d44d28d18df4bd6bb11dc",
            "dfa83106128440df927336ca0e100313",
            "53cb923e5f0341d68ccda91e7aeb5c7b",
            "8d9c6648dfec4239a44721328537e37e",
            "e894f2f0947c40f78267ac3060dd4ebc",
            "f97ffbc01d2749379a3e97912416841d",
            "60e22d9b2b774f6ca263226d13b6bfe8",
            "5307148961404d59b5b77ef6ff467ed5",
            "4505d6ad420c4e1a9247abb5c39489b7",
            "88bc99ddf0a84279aa6991607ffea630",
            "53425868705e4391b1e1d290bc74a4b9",
            "c9016c150de6427bb2ec5781fab51760"
          ]
        },
        "id": "4QFG1QjIfbXP",
        "outputId": "f06c5d6d-8f49-47e2-e549-4675e756478e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a076676150744ae4b6fce03bddbfc2bb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "configuration_prismatic.py: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "86f44d9e3abf42dab26a3c992c00b4bf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/openvla/openvla-7b:\n",
            "- configuration_prismatic.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/auto/modeling_auto.py:2275: FutureWarning: The class `AutoModelForVision2Seq` is deprecated and will be removed in v5.0. Please use `AutoModelForImageTextToText` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modeling_prismatic.py: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dfa83106128440df927336ca0e100313"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/openvla/openvla-7b:\n",
            "- modeling_prismatic.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Globally patched: transformers_modules.openvla.openvla_hyphen_7b.31f090d05236101ebfc381b61c674dd4746d4ce0.modeling_prismatic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists(save_directory) and len(os.listdir(save_directory)) > 0:\n",
        "    print(\"Found local weights! Loading from disk (No download needed)...\")\n",
        "    load_path = save_directory\n",
        "else:\n",
        "    print(\"Local weights not found. Downloading shards (This will take 10+ mins)...\")\n",
        "    load_path = model_id\n",
        "\n",
        "vla = AutoModelForVision2Seq.from_pretrained(\n",
        "    load_path,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    low_cpu_mem_usage=True,\n",
        "    trust_remote_code=True,\n",
        "    load_in_4bit=True,\n",
        "    attn_implementation=\"sdpa\",\n",
        "    resume_download=True,\n",
        "    device_map=\"auto\"\n",
        ").to(\"cuda\")\n",
        "\n",
        "if load_path == model_id:\n",
        "    print(\"Saving model to local disk for future use...\")\n",
        "    vla.save_pretrained(save_directory)\n",
        "    processor.save_pretrained(save_directory)\n",
        "    print(f\"✅ Model saved to {save_directory}. Future errors won't require a re-download.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443,
          "referenced_widgets": [
            "c1ade7c279444b32a0e81b2433da3a5c",
            "65358f198fb140468b467fa717292713",
            "4055ad39a677463dbf1cb0e3927879ed",
            "9ce586ecd2634922bc72d3545706e295",
            "89eb221312914933a8d192badfd469af",
            "ffd184ee14ab41828dc77bf9ad24406f",
            "d389ce838548427eafb0b6813876d190",
            "54330fc563ba45d78d2295ba4d6e9400",
            "2a35ace1169d492ca5e6e6934391ddc6",
            "c08ae4e94037411788ed4a16483dd107",
            "4195a550a7684a78abc506dd98281586",
            "96363c4380c64c3bb0e9e87335a57f3b",
            "b1c439d03ff8490daefdcb83522d94d5",
            "72f3b153109145b685903ad3b3ddf890",
            "2fc7f43081ef403a9c48d91001e5bb5f",
            "09fed0760d624bdfb6c69ad3079e99a7",
            "345507261a224c5196a3de7bf4474601",
            "fa935469785f4951a0832661f2d98ab9",
            "15b19407f48d40d2a81d08cb8f2a004a",
            "b4c2047ccf804f99afa18f876b742b2b",
            "0228e0b6632a43f189d6319adaf8da0b",
            "e54e9dd0ac0748588bedbf519b24f2c1",
            "87434e4b9c1d42d385eea408959d0af5",
            "4a5f4d2cc6c1425fa1e8a6fb1742586d",
            "44e935370f474ef39b1f43333156687b",
            "0539dc70ec5940b8b2c2342ec727625e",
            "aca2491e81714888ba72fb9c3e4ff0d4",
            "15d11afefa904fd58057ccada896556f",
            "2bb04515aad946dbad016aef6b754ecd",
            "fb366a3c67964eb088582332cf8a142c",
            "115caa6c559a400eacc66f473736cb65",
            "4a043955c6434015bb1657e64f53efae",
            "6c3ccd1bfe244d9db4f196565969e7c0",
            "c3d5fdbb00ec4c598c5625e7e6c0fd6c",
            "746ebb9b9135404e9c615894598dd9ca",
            "caef39faac1e4d25bc765e9c3c94b09b",
            "d7353d9451ad48ce97170bc240026800",
            "d6f7662c505840069811177b91d6d88c",
            "d092745b365049d0bf708d0eea897531",
            "18899f91c6cc4b52b901799ce21854f2",
            "4bd67acaea08412e94ad2279e1802a8b",
            "44365310814a4514b5360465135860c1",
            "1f61231e653043689017ba71430ed033",
            "c1ff879fdca44b5ba07dff10ed795223",
            "2d2ec7aac4094de6958dbc5751659389",
            "a64dae0a27af4504b1fd0b8a58ff8c77",
            "7e69c1993bb245c0b7615690f28c3477",
            "6c0572d6090d4049ae1474bb61695b74",
            "d1088bad50ec4671af4743fed866befb",
            "1ce8be20aca44c3bb08d6cb81344a7c3",
            "5ecf7db2bf8b40579685624a9c94ab94",
            "106b6fcbd8184890aec7dcdbad3e5c18",
            "2fc0df7de4cf46ed909fede2e8ec044e",
            "5997d8d0dc514c2e8ec314112124306a",
            "2d8bcdf40bd6468eb667a77aa43d9cfc",
            "45f825d17d264cbd9c3a41662051ec66",
            "ca640726f9144aef8908fb4991aa250c",
            "0e6579ec6759495c8d1a87efb60a3b27",
            "619dd55a6ac9427a8be95e45b33210e6",
            "cf5ab96247784985ae279b458466bf1b",
            "4db2678021dc40b88856b1ae59888b9c",
            "3977c3c8fdea43f699923deaefc0b777",
            "20be3b13909140e3a547ad7a4895d883",
            "1c95671272714dc191dc5688d140cb6b",
            "8a0dd23f88664b15a0e4d8db6257dc6f",
            "b8b216eb62aa4f3bbe267243db613fce",
            "79704481590f48afbea2554653b8891d",
            "86f7433f17d948898f51687fe01a49d8",
            "f01778b7202648208f61c1a9a26d7483",
            "3e5a3192a3a9473192ef2f4059ee5fcd",
            "34726648d7254779a3be34d3d53427c4",
            "4d81b6e381d644be92f21c3cbe2580b2",
            "af04bbd99a6048db835e82a63585beac",
            "0fb5e3870dde4cdf991240af073879ff",
            "7fdbcd2943984b95809e6fd56c41c1e4",
            "134ea5113c6042ea8e83ad40ec081e3c",
            "a2b6f4ff4a074ea38a6815e719ac3e1b"
          ]
        },
        "id": "4T-tgAyJppxG",
        "outputId": "6e0c9cd8-04f3-4777-dfc2-518291fcfff6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/models/auto/modeling_auto.py:2284: FutureWarning: The class `AutoModelForVision2Seq` is deprecated and will be removed in v5.0. Please use `AutoModelForImageTextToText` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Local weights not found. Downloading shards (This will take 10+ mins)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c1ade7c279444b32a0e81b2433da3a5c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "96363c4380c64c3bb0e9e87335a57f3b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00003.safetensors:   0%|          | 0.00/6.97G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "87434e4b9c1d42d385eea408959d0af5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00003.safetensors:   0%|          | 0.00/6.95G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c3d5fdbb00ec4c598c5625e7e6c0fd6c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00003-of-00003.safetensors:   0%|          | 0.00/1.16G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2d2ec7aac4094de6958dbc5751659389"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:transformers_modules.openvla.openvla_hyphen_7b.31f090d05236101ebfc381b61c674dd4746d4ce0.modeling_prismatic:Expected `transformers==4.40.1` and `tokenizers==0.19.1` but got `transformers==4.57.3` and `tokenizers==0.22.2`; there might be inference-time regressions due to dependency changes. If in doubt, pleaseuse the above versions.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "45f825d17d264cbd9c3a41662051ec66"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/136 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "79704481590f48afbea2554653b8891d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model to local disk for future use...\n",
            "✅ Model saved to ./vla_model_local. Future errors won't require a re-download.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y timm\n",
        "!pip install -q \"timm==0.9.12\""
      ],
      "metadata": {
        "id": "wsWnYaM-hd63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9eeb8fbb-c66f-4a7a-d91f-13f3bf1a2d09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: timm 1.0.24\n",
            "Uninstalling timm-1.0.24:\n",
            "  Successfully uninstalled timm-1.0.24\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import timm\n",
        "print(timm.__version__)"
      ],
      "metadata": {
        "id": "UVIo7Q0kWV2Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68df5cff-f534-41f6-9416-4705479eb203"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "H1hsnqxYWWbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vla.eval()"
      ],
      "metadata": {
        "id": "0MSpnwEkWWi0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51746f62-f094-414e-b94a-7eae9712bbde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OpenVLAForActionPrediction(\n",
              "  (vision_backbone): PrismaticVisionBackbone(\n",
              "    (featurizer): VisionTransformer(\n",
              "      (patch_embed): PatchEmbed(\n",
              "        (proj): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14))\n",
              "        (norm): Identity()\n",
              "      )\n",
              "      (pos_drop): Dropout(p=0.0, inplace=False)\n",
              "      (patch_drop): Identity()\n",
              "      (norm_pre): Identity()\n",
              "      (blocks): Sequential(\n",
              "        (0): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear4bit(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): LayerScale()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear4bit(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear4bit(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): LayerScale()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (1): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear4bit(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): LayerScale()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear4bit(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear4bit(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): LayerScale()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (2): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear4bit(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): LayerScale()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear4bit(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear4bit(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): LayerScale()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (3): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear4bit(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): LayerScale()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear4bit(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear4bit(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): LayerScale()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (4): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear4bit(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): LayerScale()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear4bit(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear4bit(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): LayerScale()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (5): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear4bit(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): LayerScale()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear4bit(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear4bit(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): LayerScale()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (6): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear4bit(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): LayerScale()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear4bit(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear4bit(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): LayerScale()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (7): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear4bit(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): LayerScale()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear4bit(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear4bit(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): LayerScale()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (8): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear4bit(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): LayerScale()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear4bit(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear4bit(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): LayerScale()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (9): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear4bit(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): LayerScale()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear4bit(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear4bit(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): LayerScale()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (10): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear4bit(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): LayerScale()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear4bit(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear4bit(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): LayerScale()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (11): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear4bit(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): LayerScale()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear4bit(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear4bit(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): LayerScale()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (12): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear4bit(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): LayerScale()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear4bit(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear4bit(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): LayerScale()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (13): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear4bit(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): LayerScale()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear4bit(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear4bit(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): LayerScale()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (14): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear4bit(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): LayerScale()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear4bit(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear4bit(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): LayerScale()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (15): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear4bit(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): LayerScale()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear4bit(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear4bit(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): LayerScale()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (16): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear4bit(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): LayerScale()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear4bit(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear4bit(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): LayerScale()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (17): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear4bit(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): LayerScale()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear4bit(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear4bit(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): LayerScale()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (18): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear4bit(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): LayerScale()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear4bit(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear4bit(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): LayerScale()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (19): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear4bit(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): LayerScale()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear4bit(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear4bit(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): LayerScale()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (20): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear4bit(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): LayerScale()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear4bit(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear4bit(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): LayerScale()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (21): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear4bit(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): LayerScale()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear4bit(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear4bit(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): LayerScale()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (22): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear4bit(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): LayerScale()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear4bit(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear4bit(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): LayerScale()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (23): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear4bit(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): LayerScale()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear4bit(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear4bit(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): LayerScale()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "      )\n",
              "      (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "      (fc_norm): Identity()\n",
              "      (head_drop): Dropout(p=0.0, inplace=False)\n",
              "      (head): Identity()\n",
              "    )\n",
              "    (fused_featurizer): VisionTransformer(\n",
              "      (patch_embed): PatchEmbed(\n",
              "        (proj): Conv2d(3, 1152, kernel_size=(14, 14), stride=(14, 14))\n",
              "        (norm): Identity()\n",
              "      )\n",
              "      (pos_drop): Dropout(p=0.0, inplace=False)\n",
              "      (patch_drop): Identity()\n",
              "      (norm_pre): Identity()\n",
              "      (blocks): Sequential(\n",
              "        (0): Block(\n",
              "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear4bit(in_features=1152, out_features=3456, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear4bit(in_features=1152, out_features=1152, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear4bit(in_features=1152, out_features=4304, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear4bit(in_features=4304, out_features=1152, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (1): Block(\n",
              "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear4bit(in_features=1152, out_features=3456, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear4bit(in_features=1152, out_features=1152, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear4bit(in_features=1152, out_features=4304, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear4bit(in_features=4304, out_features=1152, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (2): Block(\n",
              "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear4bit(in_features=1152, out_features=3456, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear4bit(in_features=1152, out_features=1152, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear4bit(in_features=1152, out_features=4304, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear4bit(in_features=4304, out_features=1152, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (3): Block(\n",
              "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear4bit(in_features=1152, out_features=3456, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear4bit(in_features=1152, out_features=1152, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear4bit(in_features=1152, out_features=4304, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear4bit(in_features=4304, out_features=1152, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (4): Block(\n",
              "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear4bit(in_features=1152, out_features=3456, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear4bit(in_features=1152, out_features=1152, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear4bit(in_features=1152, out_features=4304, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear4bit(in_features=4304, out_features=1152, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (5): Block(\n",
              "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear4bit(in_features=1152, out_features=3456, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear4bit(in_features=1152, out_features=1152, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear4bit(in_features=1152, out_features=4304, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear4bit(in_features=4304, out_features=1152, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (6): Block(\n",
              "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear4bit(in_features=1152, out_features=3456, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear4bit(in_features=1152, out_features=1152, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear4bit(in_features=1152, out_features=4304, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear4bit(in_features=4304, out_features=1152, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (7): Block(\n",
              "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear4bit(in_features=1152, out_features=3456, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear4bit(in_features=1152, out_features=1152, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear4bit(in_features=1152, out_features=4304, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear4bit(in_features=4304, out_features=1152, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (8): Block(\n",
              "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear4bit(in_features=1152, out_features=3456, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear4bit(in_features=1152, out_features=1152, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear4bit(in_features=1152, out_features=4304, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear4bit(in_features=4304, out_features=1152, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (9): Block(\n",
              "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear4bit(in_features=1152, out_features=3456, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear4bit(in_features=1152, out_features=1152, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear4bit(in_features=1152, out_features=4304, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear4bit(in_features=4304, out_features=1152, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (10): Block(\n",
              "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear4bit(in_features=1152, out_features=3456, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear4bit(in_features=1152, out_features=1152, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear4bit(in_features=1152, out_features=4304, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear4bit(in_features=4304, out_features=1152, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (11): Block(\n",
              "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear4bit(in_features=1152, out_features=3456, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear4bit(in_features=1152, out_features=1152, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear4bit(in_features=1152, out_features=4304, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear4bit(in_features=4304, out_features=1152, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (12): Block(\n",
              "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear4bit(in_features=1152, out_features=3456, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear4bit(in_features=1152, out_features=1152, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear4bit(in_features=1152, out_features=4304, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear4bit(in_features=4304, out_features=1152, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (13): Block(\n",
              "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear4bit(in_features=1152, out_features=3456, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear4bit(in_features=1152, out_features=1152, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear4bit(in_features=1152, out_features=4304, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear4bit(in_features=4304, out_features=1152, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (14): Block(\n",
              "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear4bit(in_features=1152, out_features=3456, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear4bit(in_features=1152, out_features=1152, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear4bit(in_features=1152, out_features=4304, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear4bit(in_features=4304, out_features=1152, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (15): Block(\n",
              "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear4bit(in_features=1152, out_features=3456, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear4bit(in_features=1152, out_features=1152, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear4bit(in_features=1152, out_features=4304, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear4bit(in_features=4304, out_features=1152, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (16): Block(\n",
              "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear4bit(in_features=1152, out_features=3456, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear4bit(in_features=1152, out_features=1152, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear4bit(in_features=1152, out_features=4304, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear4bit(in_features=4304, out_features=1152, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (17): Block(\n",
              "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear4bit(in_features=1152, out_features=3456, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear4bit(in_features=1152, out_features=1152, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear4bit(in_features=1152, out_features=4304, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear4bit(in_features=4304, out_features=1152, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (18): Block(\n",
              "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear4bit(in_features=1152, out_features=3456, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear4bit(in_features=1152, out_features=1152, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear4bit(in_features=1152, out_features=4304, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear4bit(in_features=4304, out_features=1152, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (19): Block(\n",
              "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear4bit(in_features=1152, out_features=3456, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear4bit(in_features=1152, out_features=1152, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear4bit(in_features=1152, out_features=4304, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear4bit(in_features=4304, out_features=1152, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (20): Block(\n",
              "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear4bit(in_features=1152, out_features=3456, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear4bit(in_features=1152, out_features=1152, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear4bit(in_features=1152, out_features=4304, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear4bit(in_features=4304, out_features=1152, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (21): Block(\n",
              "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear4bit(in_features=1152, out_features=3456, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear4bit(in_features=1152, out_features=1152, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear4bit(in_features=1152, out_features=4304, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear4bit(in_features=4304, out_features=1152, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (22): Block(\n",
              "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear4bit(in_features=1152, out_features=3456, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear4bit(in_features=1152, out_features=1152, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear4bit(in_features=1152, out_features=4304, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear4bit(in_features=4304, out_features=1152, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (23): Block(\n",
              "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear4bit(in_features=1152, out_features=3456, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear4bit(in_features=1152, out_features=1152, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear4bit(in_features=1152, out_features=4304, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear4bit(in_features=4304, out_features=1152, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (24): Block(\n",
              "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear4bit(in_features=1152, out_features=3456, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear4bit(in_features=1152, out_features=1152, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear4bit(in_features=1152, out_features=4304, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear4bit(in_features=4304, out_features=1152, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (25): Block(\n",
              "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear4bit(in_features=1152, out_features=3456, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear4bit(in_features=1152, out_features=1152, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear4bit(in_features=1152, out_features=4304, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear4bit(in_features=4304, out_features=1152, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (26): Block(\n",
              "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear4bit(in_features=1152, out_features=3456, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear4bit(in_features=1152, out_features=1152, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear4bit(in_features=1152, out_features=4304, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear4bit(in_features=4304, out_features=1152, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "      )\n",
              "      (norm): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn_pool): AttentionPoolLatent(\n",
              "        (q): Linear4bit(in_features=1152, out_features=1152, bias=True)\n",
              "        (kv): Linear4bit(in_features=1152, out_features=2304, bias=True)\n",
              "        (q_norm): Identity()\n",
              "        (k_norm): Identity()\n",
              "        (proj): Linear4bit(in_features=1152, out_features=1152, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "        (norm): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): Mlp(\n",
              "          (fc1): Linear4bit(in_features=1152, out_features=4304, bias=True)\n",
              "          (act): GELU(approximate='none')\n",
              "          (drop1): Dropout(p=0.0, inplace=False)\n",
              "          (norm): Identity()\n",
              "          (fc2): Linear4bit(in_features=4304, out_features=1152, bias=True)\n",
              "          (drop2): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (fc_norm): Identity()\n",
              "      (head_drop): Dropout(p=0.0, inplace=False)\n",
              "      (head): Identity()\n",
              "    )\n",
              "  )\n",
              "  (projector): PrismaticProjector(\n",
              "    (fc1): Linear4bit(in_features=2176, out_features=8704, bias=True)\n",
              "    (fc2): Linear4bit(in_features=8704, out_features=4096, bias=True)\n",
              "    (fc3): Linear4bit(in_features=4096, out_features=4096, bias=True)\n",
              "    (act_fn1): GELU(approximate='none')\n",
              "    (act_fn2): GELU(approximate='none')\n",
              "  )\n",
              "  (language_model): LlamaForCausalLM(\n",
              "    (model): LlamaModel(\n",
              "      (embed_tokens): Embedding(32064, 4096, padding_idx=32000)\n",
              "      (layers): ModuleList(\n",
              "        (0-31): 32 x LlamaDecoderLayer(\n",
              "          (self_attn): LlamaAttention(\n",
              "            (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "            (k_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "            (v_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "            (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "          )\n",
              "          (mlp): LlamaMLP(\n",
              "            (gate_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
              "            (up_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
              "            (down_proj): Linear4bit(in_features=11008, out_features=4096, bias=False)\n",
              "            (act_fn): SiLUActivation()\n",
              "          )\n",
              "          (input_layernorm): LlamaRMSNorm((4096,), eps=1e-06)\n",
              "          (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-06)\n",
              "        )\n",
              "      )\n",
              "      (norm): LlamaRMSNorm((4096,), eps=1e-06)\n",
              "      (rotary_emb): LlamaRotaryEmbedding()\n",
              "    )\n",
              "    (lm_head): Linear(in_features=4096, out_features=32064, bias=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q apache_beam tfds-nightly"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i296iBce2QzB",
        "outputId": "2efe307b-1bbe-4fa6-a177-1a70999a34e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.9/16.9 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.9/96.9 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.3/46.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m331.1/331.1 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "grpcio-status 1.71.2 requires grpcio>=1.71.2, but you have grpcio 1.65.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading the first shard (approx 100MB)\n",
        "!wget https://rail.eecs.berkeley.edu/datasets/bridge_release/data/tfds/bridge_dataset/1.0.0/bridge_dataset-train.tfrecord-00000-of-01024"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "norwiM-U1d_a",
        "outputId": "95b8b86a-3d6e-4750-d5bc-38c263236db0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-01-18 17:23:00--  https://rail.eecs.berkeley.edu/datasets/bridge_release/data/tfds/bridge_dataset/1.0.0/bridge_dataset-train.tfrecord-00000-of-01024\n",
            "Resolving rail.eecs.berkeley.edu (rail.eecs.berkeley.edu)... 128.32.244.190\n",
            "Connecting to rail.eecs.berkeley.edu (rail.eecs.berkeley.edu)|128.32.244.190|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 108381239 (103M)\n",
            "Saving to: ‘bridge_dataset-train.tfrecord-00000-of-01024’\n",
            "\n",
            "bridge_dataset-trai 100%[===================>] 103.36M  41.2MB/s    in 2.5s    \n",
            "\n",
            "2026-01-18 17:23:03 (41.2 MB/s) - ‘bridge_dataset-train.tfrecord-00000-of-01024’ saved [108381239/108381239]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Path to the shard of data.\n",
        "shard_path = \"bridge_dataset-train.tfrecord-00000-of-01024\""
      ],
      "metadata": {
        "id": "P1I3e9Cb1eNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the 'RLDS' structure for Bridge V2\n",
        "# This matches the schema found at the URL\n",
        "def parse_fn(example_proto):\n",
        "    features = {\n",
        "        'steps/observation/image': tf.io.FixedLenSequenceFeature([], tf.string, allow_missing=True),\n",
        "        'steps/observation/natural_language_instruction': tf.io.FixedLenSequenceFeature([], tf.string, allow_missing=True),\n",
        "        'steps/action': tf.io.FixedLenSequenceFeature([7], tf.float32, allow_missing=True),\n",
        "    }\n",
        "    return tf.io.parse_single_example(example_proto, features)"
      ],
      "metadata": {
        "id": "y7etFHgK1eWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_dataset = tf.data.TFRecordDataset(shard_path)\n",
        "parsed_dataset = raw_dataset.map(parse_fn)"
      ],
      "metadata": {
        "id": "PhzOsaIFWWxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_example = next(iter(tf.data.TFRecordDataset(shard_path)))\n",
        "example = tf.train.Example.FromString(raw_example.numpy())\n",
        "print(\"Keys available in this shard:\", example.features.feature.keys())"
      ],
      "metadata": {
        "id": "Q0k4-ji2JIJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shard_path = \"bridge_dataset-train.tfrecord-00000-of-01024\"\n",
        "\n",
        "def parse_fn_bridge_v1(example_proto):\n",
        "    features = {\n",
        "        'steps/language_instruction': tf.io.FixedLenSequenceFeature([], tf.string, allow_missing=True),\n",
        "        'steps/observation/image_2': tf.io.FixedLenSequenceFeature([], tf.string, allow_missing=True),\n",
        "        'steps/action': tf.io.FixedLenSequenceFeature([7], tf.float32, allow_missing=True),\n",
        "    }\n",
        "    return tf.io.parse_single_example(example_proto, features)\n",
        "\n",
        "raw_dataset = tf.data.TFRecordDataset(shard_path)\n",
        "parsed_dataset = raw_dataset.map(parse_fn_bridge_v1)\n",
        "\n",
        "for episode in parsed_dataset.take(100):\n",
        "    instructions = episode['steps/language_instruction'].numpy()\n",
        "\n",
        "    if len(instructions) > 0:\n",
        "        instruction = instructions[0].decode('utf-8')\n",
        "\n",
        "        if \"pick\" in instruction.lower():\n",
        "            img_seq = episode['steps/observation/image_2'].numpy()\n",
        "\n",
        "            if len(img_seq) > 0:\n",
        "                image_pil = Image.fromarray(tf.io.decode_image(img_seq[0]).numpy())\n",
        "\n",
        "                inputs = processor(text=instruction, images=image_pil, return_tensors=\"pt\").to(\"cuda\")\n",
        "                inputs_dict = {k: v for k, v in inputs.items()}\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    # Unpacking dict to provide individual tensors to the model\n",
        "                    predicted_action = vla.predict_action(**inputs_dict, unnorm_key=\"bridge_orig\")\n",
        "\n",
        "                gt_action = episode['steps/action'].numpy()[0]\n",
        "\n",
        "                print(f\"🎯 Task: {instruction}\")\n",
        "                print(f\"Predicted XYZ: {predicted_action[:3]}\")\n",
        "                print(f\"Ground Truth XYZ: {gt_action[:3]}\")\n",
        "                print(f\"MSE: {np.mean((predicted_action[:3] - gt_action[:3])**2):.6f}\")\n",
        "                break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsoI6RBMJH3A",
        "outputId": "7586acc0-b941-4955-be85-64e842e81aea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎯 Task: Picked the piece of chocolate and put it into the drawer\n",
            "Predicted XYZ: [-0.00020879 -0.00042412  0.00703386]\n",
            "Ground Truth XYZ: [0.0000000e+00 0.0000000e+00 1.3877788e-17]\n",
            "MSE: 0.000017\n"
          ]
        }
      ]
    }
  ]
}